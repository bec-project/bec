# This file is a template, and might need editing before it works on your project.
# Official language image. Look for the different tagged releases at:
# https://hub.docker.com/r/library/python/tags/
image: $CI_DOCKER_REGISTRY/python:3.9
#commands to run in the Docker container before starting each job.
variables:
  DOCKER_TLS_CERTDIR: ""
  OPHYD_DEVICES_BRANCH: "master"

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
      when: never
    - if: $CI_COMMIT_BRANCH


include:
  - template: Security/Secret-Detection.gitlab-ci.yml


# don't runt the pipeline for release pushes, that is with changes to semantic_release
# workflow:
#   rules:
#       - changes:
#           - ./semantic_release/__init__.py
#         when: never
#       - when: always

# different stages in the pipeline
stages:
  - Formatter
  - test # must be called test for security/secret-detection to work
  - AdditionalTests
  - End2End
  - Build
  - Deploy

.install-bec-services: &install-bec-services
    - pip install -e ./device_server
    - pip install -e ./scan_server
    - pip install -e ./scan_bundler
    - pip install -e ./bec_client
    - pip install -e ./file_writer
    - pip install -e ./scihub
    - pip install -e ./data_processing

.install-bec-services-dev: &install-bec-services-dev
    - pip install -e ./bec_lib[dev]
    - pip install -e ./device_server
    - pip install -e ./scan_server
    - pip install -e ./scan_bundler
    - pip install -e ./bec_client
    - pip install -e ./file_writer
    - pip install -e ./scihub
    - pip install -e ./data_processing

formatter:
  stage: Formatter
  needs: []
  script:
    - pip install black
    - black --check --diff --color --line-length=100 ./

pylint:
  stage: Formatter
  needs: []
  before_script:
    - pip install pylint pylint-exit anybadge
  script:
    - mkdir ./pylint
    - pylint ./data_processing/data_processing ./bec_lib/bec_lib ./scan_server/scan_server ./device_server/device_server ./scan_bundler/scan_bundler ./bec_client/bec_client ./file_writer/file_writer --output-format=text . | tee ./pylint/pylint.log || pylint-exit $?
    - PYLINT_SCORE=$(sed -n 's/^Your code has been rated at \([-0-9.]*\)\/.*/\1/p' ./pylint/pylint.log)
    - anybadge --label=Pylint --file=pylint/pylint.svg --value=$PYLINT_SCORE 2=red 4=orange 8=yellow 10=green
    - echo "Pylint score is $PYLINT_SCORE"
  artifacts:
    paths:
      - ./pylint/
    expire_in: 1 week  

pylint-check:
  stage: Formatter
  needs: []
  allow_failure: true
  before_script:
    - pip install pylint pylint-exit anybadge
    - apt-get update
    - apt-get install -y bc
  script:
    # Identify changed Python files
    - if [ "$CI_PIPELINE_SOURCE" == "merge_request_event" ]; then
        TARGET_BRANCH_COMMIT_SHA=$(git rev-parse $CI_MERGE_REQUEST_TARGET_BRANCH_NAME);
        CHANGED_FILES=$(git diff --name-only $SOURCE_BRANCH_COMMIT_SHA $TARGET_BRANCH_COMMIT_SHA | grep '\.py$' || true);
      else
        CHANGED_FILES=$(git diff --name-only $CI_COMMIT_BEFORE_SHA $CI_COMMIT_SHA | grep '\.py$' || true);
      fi
    - if [ -z "$CHANGED_FILES" ]; then echo "No Python files changed."; exit 0; fi

    # Run pylint only on changed files
    - mkdir ./pylint
    - pylint $CHANGED_FILES --output-format=text . | tee ./pylint/pylint_changed_files.log || pylint-exit $?
    - PYLINT_SCORE=$(sed -n 's/^Your code has been rated at \([-0-9.]*\)\/.*/\1/p' ./pylint/pylint_changed_files.log)
    - echo "Pylint score is $PYLINT_SCORE"

    # Fail the job if the pylint score is below 9
    - if [ "$(echo "$PYLINT_SCORE < 9" | bc)" -eq 1 ]; then echo "Your pylint score is below the acceptable threshold (9)."; exit 1; fi
  artifacts:
    paths:
      - ./pylint/
    expire_in: 1 week


tests:
  stage: test
  needs: []
  script:
    - git clone --branch $OPHYD_DEVICES_BRANCH https://oauth2:$CI_OPHYD_DEVICES_KEY@gitlab.psi.ch/bec/ophyd_devices.git
    - export OPHYD_DEVICES_PATH=$PWD/ophyd_devices
    - pip install pytest pytest-random-order pytest-cov pytest-asyncio pytest-timeout
    - apt-get install -y gcc
    - *install-bec-services-dev
    - coverage run --source=./data_processing/data_processing,./bec_lib/bec_lib,./device_server/device_server,./scan_server/scan_server,./scan_bundler/scan_bundler,./bec_client/bec_client,./file_writer/file_writer,./scihub/scihub --omit=*/bec_client/bec_client/plugins/*,*/bec_client/scripts/* -m pytest -v --junitxml=report.xml --random-order ./data_processing/tests ./scan_server/tests ./device_server/tests ./scan_bundler/tests ./bec_client/tests/client_tests ./file_writer/tests ./scihub/tests ./bec_lib/tests
    - coverage report
    - coverage xml
  coverage: '/(?i)total.*? (100(?:\.0+)?\%|[1-9]?\d(?:\.\d+)?\%)$/'
  artifacts:
    reports:
      junit: report.xml
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml   

tests-3.10:
  stage: AdditionalTests
  image: $CI_DOCKER_REGISTRY/python:3.10
  needs: ["tests"]
  allow_failure: true
  script:
    - git clone --branch $OPHYD_DEVICES_BRANCH https://oauth2:$CI_OPHYD_DEVICES_KEY@gitlab.psi.ch/bec/ophyd_devices.git
    - export OPHYD_DEVICES_PATH=$PWD/ophyd_devices
    - pip install pytest pytest-random-order pytest-cov pytest-asyncio pytest-timeout
    - apt-get install -y gcc
    - *install-bec-services-dev
    - pytest -v --junitxml=report.xml --random-order ./data_processing/tests ./bec_lib/tests ./scan_server/tests ./device_server/tests ./scan_bundler/tests ./bec_client/tests/client_tests ./file_writer/tests ./scihub/tests

tests-3.11:
  extends: "tests-3.10"
  stage: AdditionalTests
  image: $CI_DOCKER_REGISTRY/python:3.11
  allow_failure: true

tests-3.12:
  extends: "tests-3.10"
  stage: AdditionalTests
  image: $CI_DOCKER_REGISTRY/python:3.12
  allow_failure: true

end-2-end:
  stage: End2End
  needs: []
  image: $CI_DOCKER_REGISTRY/docker:23-dind
  services:
    - name: docker:dind
      entrypoint: ["dockerd-entrypoint.sh", "--tls=false"]
  allow_failure: false
  artifacts:
    when: on_failure
    paths:
      - ScanServer.log
      - ScanBundler.log
      - DeviceServer.log
      - BECClient.log
      - FileWriterManager.log
      - SciHub.log
      - DAPServer.log
    expire_in: 1 week

  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "production"'
  script:
    # spin up redis
    - docker run --network=host -d --name redis-test redis
    - apk update; apk upgrade; apk add git

    # get ophyd devices repo (needed for the device_server)
    - git clone --branch $OPHYD_DEVICES_BRANCH https://oauth2:$CI_OPHYD_DEVICES_KEY@gitlab.psi.ch/bec/ophyd_devices.git

    # initialize the database with the test config
    - docker build -t init_config:test -f ./ci/config_init_dockerfile --build-arg PY_VERSION=3.9 .
    - docker run --network=host --name init_config init_config:test
    - docker build -t scihub:test -f ./scihub/Dockerfile --build-arg PY_VERSION=3.9 .
    - docker run --network=host -d --name scihub scihub:test

    # build scan_bundler, scan_server, device_server and file_writer
    - docker build -t scan_bundler:test -f ./scan_bundler/Dockerfile --build-arg PY_VERSION=3.9 .
    - docker build -t scan_server:test -f ./scan_server/Dockerfile --build-arg PY_VERSION=3.9 .
    - docker build -t device_server:test -f ./device_server/Dockerfile --build-arg PY_VERSION=3.9 .
    - docker build -t file_writer:test -f ./file_writer/Dockerfile --build-arg PY_VERSION=3.9 .
    - docker build -t data_processing:test -f ./data_processing/Dockerfile --build-arg PY_VERSION=3.9 .

    # run scan_bundler, scan_server, device_server and file_writer
    - docker run --network=host -d --name device_server device_server:test
    - docker run --network=host -d --name scan_server scan_server:test
    - docker run --network=host -d --name scan_bundler scan_bundler:test
    - docker run --network=host -d --name file_writer file_writer:test
    - docker run --network=host -d --name data_processing data_processing:test

    # build and run the tests
    - docker build -t en2end_client:test -f ./bec_client/tests/Dockerfile --build-arg PY_VERSION=3.9 .
    - docker run --network=host --name end2end_client en2end_client:test

  after_script:
    # copy the log files to the project directory in order to be reachable by git artifacts
    - docker cp scan_server:/code/bec/scan_server/ScanServer.log $CI_PROJECT_DIR/ScanServer.log
    - docker cp scan_bundler:/code/bec/scan_bundler/ScanBundler.log $CI_PROJECT_DIR/ScanBundler.log
    - docker cp device_server:/code/bec/device_server/DeviceServer.log $CI_PROJECT_DIR/DeviceServer.log
    - docker cp file_writer:/code/bec/file_writer/FileWriterManager.log $CI_PROJECT_DIR/FileWriterManager.log
    - docker cp end2end_client:/code/bec/bec_client/BECClient.log $CI_PROJECT_DIR/BECClient.log
    - docker cp scihub:/code/bec/scihub/SciHub.log $CI_PROJECT_DIR/SciHub.log
    - docker cp data_processing:/code/bec/data_processing/DAPServer.log $CI_PROJECT_DIR/DAPServer.log

# end-2-end-scibec:
#   extends: "end-2-end"
#   allow_failure: true
#   script:
#     # spin up redis, mongo and scibec
#     - docker-compose -f ./ci/docker-compose.yaml up -d
#     - apk update; apk upgrade; apk add curl; apk add git; apk add gcc

#     # get ophyd devices repo (needed for the device_server)
#     - git clone --branch $OPHYD_DEVICES_BRANCH https://oauth2:$CI_OPHYD_DEVICES_KEY@gitlab.psi.ch/bec/ophyd_devices.git

#     # make sure that the API server is healthy and ready
#     - timeout 120 /bin/sh -c -- 'while true; do res=$(curl -X "GET" --max-time 3 "http://docker:3030/sessions"); if [ ! -z "$res" ]; then exit 0; fi; sleep 1; done;'

#     # initialize the database with the test config
#     - docker build -t init_scibec:test -f ./scibec/init_scibec/Dockerfile .
#     - docker run --network=host --name init_scibec init_scibec:test
#     - docker build -t scihub:test -f ./scihub/Dockerfile .
#     - docker run --network=host -d --name scihub scihub:test

#     # build scan_bundler, scan_server, device_server and file_writer
#     - docker build -t scan_bundler:test -f ./scan_bundler/Dockerfile .
#     - docker build -t scan_server:test -f ./scan_server/Dockerfile .
#     - docker build -t device_server:test -f ./device_server/Dockerfile .
#     - docker build -t file_writer:test -f ./file_writer/Dockerfile .

#     # run scan_bundler, scan_server, device_server and file_writer
#     - docker run --network=host -d --name device_server device_server:test
#     - docker run --network=host -d --name scan_server scan_server:test
#     - docker run --network=host -d --name scan_bundler scan_bundler:test
#     - docker run --network=host -d --name file_writer file_writer:test

#     # build and run the tests
#     - docker build -t en2end_client:test -f ./bec_client/tests/Dockerfile .
#     - docker run --network=host --name end2end_client en2end_client:test


end-2-end-conda:
  stage: End2End
  needs: []
  image: continuumio/miniconda3
  allow_failure: false
  script:
    - apt-get update
    - apt-get install -y tmux
    - conda config --set always_yes yes --set changeps1 no
    - conda create -q -n test-environment python=3.9
    - conda init bash
    - source ~/.bashrc
    - conda activate test-environment

    - conda install redis
    - redis-server --daemonize yes

    # get ophyd devices repo (needed for the device_server)
    - git clone --branch $OPHYD_DEVICES_BRANCH https://oauth2:$CI_OPHYD_DEVICES_KEY@gitlab.psi.ch/bec/ophyd_devices.git
    - export OPHYD_DEVICES_PATH=$PWD/ophyd_devices

    - source ./bin/install_bec_dev.sh
    - python ./bec_lib/util_scripts/init_config.py --config ./bec_lib/bec_lib/configs/demo_config.yaml

    - bec-server start --config ./ci/test_config.yaml

    - pip install pytest pytest-random-order pytest-cov pytest-asyncio pytest-timeout
    - cd ./bec_client
    - pytest -v ./tests/end-2-end/test_scans.py::test_grid_scan

  artifacts:
    when: on_failure
    paths:
      - ScanServer.log
      - ScanBundler.log
      - DeviceServer.log
      - BECClient.log
      - FileWriterManager.log
      - SciHub.log
      - DAPServer.log
    expire_in: 1 week

  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "production"'

trigger_bec-widgets:
  trigger:
    project: bec/bec-widgets
    strategy: depend
  allow_failure: true
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "production"'

trigger_ophyd-devices:
  trigger:
    project: bec/ophyd_devices
    strategy: depend
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "production"'

semver:
  stage: Build
  needs: ["tests"]
  script:
    - git config --global user.name "ci_update_bot"
    - git config --global user.email "ci_update_bot@bec.ch"
    - git checkout "$CI_COMMIT_REF_NAME"
    - git reset --hard origin/"$CI_COMMIT_REF_NAME"

    # delete all local tags
    - git tag -l | xargs git tag -d
    - git fetch --tags
    - git tag

    # build
    - pip install python-semantic-release==7.* wheel build
    - export GL_TOKEN=$CI_UPDATES
    - export REPOSITORY_USERNAME=__token__
    - export REPOSITORY_PASSWORD=$CI_PYPI_TOKEN
    - >
      semantic-release publish -v DEBUG
      -D version_variable=./semantic_release/__init__.py:__version__,./bec_client/setup.py:__version__,./bec_lib/setup.py:__version__,./data_processing/setup.py:__version__,./device_server/setup.py:__version__,./file_writer/setup.py:__version__,./scan_bundler/setup.py:__version__,./scan_server/setup.py:__version__,./scihub/setup.py:__version__,./bec_server/setup.py:__version__
      -D hvcs=gitlab
      -D build_command="./ci/build_python_services.sh"

  allow_failure: false
  rules:
    - if: '$CI_COMMIT_REF_NAME == "master"'

dev-pages:
  stage: Deploy
  needs: ["formatter"]
  rules:
    - if: $CI_COMMIT_REF_NAME == "development"
  script:
    - git config --global user.name "ci_update_bot"
    - git config --global user.email "ci_update_bot@bec.ch"
    - git tag -f development "$CI_COMMIT_SHA"
    - git push --force origin development

    - curl -X POST -d "branches=development" -d "token=$RTD_TOKEN" https://readthedocs.org/api/v2/webhook/beamline-experiment-control/221870/
    - curl -X POST -d "branches=development" -d "token=$RTD_TOKEN_BEC" https://readthedocs.org/api/v2/webhook/bec/246899/

pages:
  stage: Deploy
  needs: ["semver"]
  variables:
    TARGET_BRANCH: $CI_COMMIT_REF_NAME
  rules:
    - if: '$CI_COMMIT_TAG != null'
      variables:
        TARGET_BRANCH: $CI_COMMIT_TAG
    - if: '$CI_COMMIT_REF_NAME == "master"'
    - if: '$CI_COMMIT_REF_NAME == "production"'
  script:
    - curl -X POST -d "branches=$CI_COMMIT_REF_NAME" -d "token=$RTD_TOKEN" https://readthedocs.org/api/v2/webhook/beamline-experiment-control/221870/
    - curl -X POST -d "branches=$CI_COMMIT_REF_NAME" -d "token=$RTD_TOKEN_BEC" https://readthedocs.org/api/v2/webhook/bec/246899/

