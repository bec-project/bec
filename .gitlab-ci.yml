# This file is a template, and might need editing before it works on your project.
# Official language image. Look for the different tagged releases at:
# https://hub.docker.com/r/library/python/tags/
image: $CI_DOCKER_REGISTRY/python:3.10
#commands to run in the Docker container before starting each job.
variables:
  DOCKER_TLS_CERTDIR: ""
  OPHYD_DEVICES_BRANCH: "master"
  BEC_WIDGETS_BRANCH: "master"

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_PIPELINE_SOURCE == "web"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
      when: never
    - if: $CI_COMMIT_BRANCH


include:
  - template: Security/Secret-Detection.gitlab-ci.yml


# don't run the pipeline for release pushes, that is with changes to semantic_release
# workflow:
#   rules:
#       - changes:
#           - ./semantic_release/__init__.py
#         when: never
#       - when: always

# different stages in the pipeline
stages:
  - Formatter
  - test # must be called test for security/secret-detection to work
  - AdditionalTests
  - End2End
  - Build
  - Deploy

.install-bec-services: &install-bec-services
    - pip install -e ./device_server
    - pip install -e ./scan_server
    - pip install -e ./scan_bundler
    - pip install -e ./bec_client
    - pip install -e ./file_writer
    - pip install -e ./scihub
    - pip install -e ./data_processing

.install-bec-services-dev: &install-bec-services-dev
    - pip install wheel
    - pip install -e ./bec_server[dev]
    - pip install -e ./bec_client[dev]
    - pip install -e ./bec_lib[dev]

formatter:
  stage: Formatter
  needs: []
  script:
    - pip install black isort
    - *install-bec-services-dev
    - isort --check --diff --line-length=100 --profile=black --multi-line=3 --trailing-comma ./
    - black --check --diff --color --line-length=100 ./

pylint:
  stage: Formatter
  needs: []
  before_script:
    - pip install pylint pylint-exit anybadge
  script:
    - mkdir ./pylint
    - pylint ./data_processing/data_processing ./bec_lib/bec_lib ./scan_server/scan_server ./device_server/device_server ./scan_bundler/scan_bundler ./bec_client/bec_client ./file_writer/file_writer --output-format=text | tee ./pylint/pylint.log || pylint-exit $?
    - PYLINT_SCORE=$(sed -n 's/^Your code has been rated at \([-0-9.]*\)\/.*/\1/p' ./pylint/pylint.log)
    - anybadge --label=Pylint --file=pylint/pylint.svg --value=$PYLINT_SCORE 2=red 4=orange 8=yellow 10=green
    - echo "Pylint score is $PYLINT_SCORE"
  artifacts:
    paths:
      - ./pylint/
    expire_in: 1 week

pylint-check:
  stage: Formatter
  needs: []
  allow_failure: true
  before_script:
    - pip install pylint pylint-exit anybadge
    - apt-get update
    - apt-get install -y bc
  script:
    # Identify changed Python files
    - if [ "$CI_PIPELINE_SOURCE" == "merge_request_event" ]; then
        TARGET_BRANCH_COMMIT_SHA=$(git rev-parse origin/$CI_MERGE_REQUEST_TARGET_BRANCH_NAME);
        CHANGED_FILES=$(git diff --name-only $TARGET_BRANCH_COMMIT_SHA HEAD | grep '\.py$' || true);
      else
        CHANGED_FILES=$(git diff --name-only $CI_COMMIT_BEFORE_SHA $CI_COMMIT_SHA | grep '\.py$' || true);
      fi
    - if [ -z "$CHANGED_FILES" ]; then echo "No Python files changed."; exit 0; fi

    - echo "Changed Python files:"
      - $CHANGED_FILES
    # Run pylint only on changed files
    - mkdir ./pylint
    - pylint $CHANGED_FILES --output-format=text | tee ./pylint/pylint_changed_files.log || pylint-exit $?
    - PYLINT_SCORE=$(sed -n 's/^Your code has been rated at \([-0-9.]*\)\/.*/\1/p' ./pylint/pylint_changed_files.log)
    - echo "Pylint score is $PYLINT_SCORE"

    # Fail the job if the pylint score is below 9
    - if [ "$(echo "$PYLINT_SCORE < 9" | bc)" -eq 1 ]; then echo "Your pylint score is below the acceptable threshold (9)."; exit 1; fi
  artifacts:
    paths:
      - ./pylint/
    expire_in: 1 week


tests:
  stage: test
  needs: []
  script:
    - git clone --branch $OPHYD_DEVICES_BRANCH https://oauth2:$CI_OPHYD_DEVICES_KEY@gitlab.psi.ch/bec/ophyd_devices.git
    - export OPHYD_DEVICES_PATH=$PWD/ophyd_devices
    - pip install pytest pytest-random-order pytest-cov pytest-timeout
    - apt-get update
    - apt-get install -y gcc
    - apt-get install -y redis
    - *install-bec-services-dev
    - coverage run --source=./data_processing/data_processing,./bec_lib/bec_lib,./device_server/device_server,./scan_server/scan_server,./scan_bundler/scan_bundler,./bec_client/bec_client,./file_writer/file_writer,./scihub/scihub --omit=*/bec_client/bec_client/plugins/*,*/bec_client/scripts/*,./bec_lib/bec_lib/tests -m pytest -v --junitxml=report.xml --random-order ./data_processing/tests ./scan_server/tests ./device_server/tests ./scan_bundler/tests ./bec_client/tests/client_tests ./file_writer/tests ./scihub/tests ./bec_lib/tests
    - coverage report
    - coverage xml
  coverage: '/(?i)total.*? (100(?:\.0+)?\%|[1-9]?\d(?:\.\d+)?\%)$/'
  artifacts:
    reports:
      junit: report.xml
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

tests-3.11:
  stage: AdditionalTests
  image: $CI_DOCKER_REGISTRY/python:3.11
  needs: ["tests"]
  allow_failure: true
  script:
    - git clone --branch $OPHYD_DEVICES_BRANCH https://oauth2:$CI_OPHYD_DEVICES_KEY@gitlab.psi.ch/bec/ophyd_devices.git
    - export OPHYD_DEVICES_PATH=$PWD/ophyd_devices
    - pip install pytest pytest-random-order pytest-cov pytest-timeout
    - apt-get update
    - apt-get install -y gcc
    - apt-get install -y redis
    - *install-bec-services-dev
    - pytest -v --junitxml=report.xml --random-order ./data_processing/tests ./bec_lib/tests ./scan_server/tests ./device_server/tests ./scan_bundler/tests ./bec_client/tests/client_tests ./file_writer/tests ./scihub/tests

tests-3.12:
  extends: "tests-3.11"
  stage: AdditionalTests
  image: $CI_DOCKER_REGISTRY/python:3.12
  allow_failure: true

end-2-end:
  stage: End2End
  needs: []
  image: $CI_DOCKER_REGISTRY/docker:23-dind
  services:
    - name: docker:dind
      entrypoint: ["dockerd-entrypoint.sh", "--tls=false"]
  allow_failure: false
  artifacts:
    when: on_failure
    paths:
      - ./*.log
    expire_in: 2 week

  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "production"'
  script:
    # build and run the tests
    - echo $OPHYD_DEVICES_BRANCH 
    - docker build -t end2end_client:test -f ./ci/Dockerfile.run_pytest --build-arg PY_VERSION=3.10 --build-arg BEC_SERVICE=bec_client --build-arg OPHYD_BRANCH=$OPHYD_DEVICES_BRANCH .
    - docker run --network=host --name end2end_client end2end_client:test

  after_script:
    # copy the log files to the project directory in order to be reachable by git artifacts
    - docker cp end2end_client:/code/bec/test_files/. $CI_PROJECT_DIR

# end-2-end-scibec:
#   extends: "end-2-end"
#   allow_failure: true
#   script:
#     # spin up redis, mongo and scibec
#     - docker-compose -f ./ci/docker-compose.yaml up -d
#     - apk update; apk upgrade; apk add curl; apk add git; apk add gcc

#     # get ophyd devices repo (needed for the device_server)
#     - git clone --branch $OPHYD_DEVICES_BRANCH https://oauth2:$CI_OPHYD_DEVICES_KEY@gitlab.psi.ch/bec/ophyd_devices.git

#     # make sure that the API server is healthy and ready
#     - timeout 120 /bin/sh -c -- 'while true; do res=$(curl -X "GET" --max-time 3 "http://docker:3030/sessions"); if [ ! -z "$res" ]; then exit 0; fi; sleep 1; done;'

#     # initialize the database with the test config
#     - docker build -t init_scibec:test -f ./scibec/init_scibec/Dockerfile .
#     - docker run --network=host --name init_scibec init_scibec:test
#     - docker build -t scihub:test -f ./scihub/Dockerfile .
#     - docker run --network=host -d --name scihub scihub:test

#     # build scan_bundler, scan_server, device_server and file_writer
#     - docker build -t scan_bundler:test -f ./scan_bundler/Dockerfile .
#     - docker build -t scan_server:test -f ./scan_server/Dockerfile .
#     - docker build -t device_server:test -f ./device_server/Dockerfile .
#     - docker build -t file_writer:test -f ./file_writer/Dockerfile .

#     # run scan_bundler, scan_server, device_server and file_writer
#     - docker run --network=host -d --name device_server device_server:test
#     - docker run --network=host -d --name scan_server scan_server:test
#     - docker run --network=host -d --name scan_bundler scan_bundler:test
#     - docker run --network=host -d --name file_writer file_writer:test

#     # build and run the tests
#     - docker build -t en2end_client:test -f ./bec_client/tests/Dockerfile .
#     - docker run --network=host --name end2end_client en2end_client:test

end-2-end-services_on_multi_hosts:
  stage: End2End
  when: manual
  needs: []
  services:
    - redis
  variables:
    STORAGE_DRIVER: vfs
  #  CI_DEBUG_SERVICES: "true"
  image: alpine:latest
  allow_failure: true
  script:
    # download buildah & podman
    - apk add buildah
    - apk add podman
    # build containers
    # /!\ build-arg is interpreted differently by podman,
    # have to use buildah here
    - buildah bud --network=host -t device_server_vm -f ./ci/Dockerfile.run_server --build-arg PY_VERSION=3.10 --build-arg BEC_SERVICE=device_server --build-arg OPHYD_BRANCH=$OPHYD_DEVICES_BRANCH
    - buildah bud --network=host -t scan_server_vm -f ./ci/Dockerfile.run_server --build-arg PY_VERSION=3.10 --build-arg BEC_SERVICE=scan_server --build-arg OPHYD_BRANCH=$OPHYD_DEVICES_BRANCH 
    - buildah bud --network=host -t scan_bundler_vm -f ./ci/Dockerfile.run_server --build-arg PY_VERSION=3.10 --build-arg BEC_SERVICE=scan_bundler --build-arg OPHYD_BRANCH=$OPHYD_DEVICES_BRANCH
    - buildah bud --network=host -t file_writer_vm -f ./ci/Dockerfile.run_server --build-arg PY_VERSION=3.10 --build-arg BEC_SERVICE=file_writer --build-arg OPHYD_BRANCH=$OPHYD_DEVICES_BRANCH
    - buildah bud --network=host -t dap_server_vm -f ./ci/Dockerfile.run_server --build-arg PY_VERSION=3.10 --build-arg BEC_SERVICE=data_processing --build-arg OPHYD_BRANCH=$OPHYD_DEVICES_BRANCH
    - buildah bud --network=host -t scihub_vm -f ./ci/Dockerfile.run_server --build-arg PY_VERSION=3.10 --build-arg BEC_SERVICE=scihub --build-arg OPHYD_BRANCH=$OPHYD_DEVICES_BRANCH
    # default service is bec_client
    - buildah bud --network=host -t end2end_client_test -f ./ci/Dockerfile.run_server --build-arg PY_VERSION=3.10

    # now for the run phase...
    - REDIS_IP=$(cat /etc/hosts | awk '{if ($2 == "redis") print $1;}')
    # Just checking that the IP is reachable from outside the container
    - ping -w 2 $REDIS_IP
    # declare env var for containers to find redis
    - export BEC_REDIS_HOST=$REDIS_IP
    # run servers
    - podman run -d --network=host --env BEC_REDIS_HOST --name device_server device_server_vm bec-device-server
    - podman run -d --network=host --env BEC_REDIS_HOST --name scan_server scan_server_vm bec-scan-server
    - podman run -d --network=host --env BEC_REDIS_HOST --name scan_bundler scan_bundler_vm bec-scan-bundler
    - podman run -d --network=host --env BEC_REDIS_HOST --name file_writer file_writer_vm bec-file-writer
    - podman run -d --network=host --env BEC_REDIS_HOST --name dap dap_server_vm bec-dap
    - podman run -d --network=host --env BEC_REDIS_HOST --name scihub scihub_vm bec-scihub
    # start end-to-end test, using previously started servers and previously running redis instance 
    - podman run --network=host --env BEC_REDIS_HOST --name end2end_test end2end_client_test pytest --bec-redis-host $BEC_REDIS_HOST -v --random-order tests/end-2-end || true
    # copy the log files to the project directory in order to be reachable by git artifacts
    - podman cp device_server:/code/bec/device_server/DeviceServer.log $CI_PROJECT_DIR/
    - podman cp scan_server:/code/bec/scan_server/ScanServer.log $CI_PROJECT_DIR/
    - podman cp scan_bundler:/code/bec/scan_bundler/ScanBundler.log $CI_PROJECT_DIR/
    - podman cp file_writer:/code/bec/file_writer/FileWriterManager.log $CI_PROJECT_DIR/
    - podman cp scihub:/code/bec/scihub/SciHub.log $CI_PROJECT_DIR/
    - podman cp dap:/code/bec/data_processing/DAPServer.log $CI_PROJECT_DIR/
    - podman cp end2end_test:/code/bec/bec_client/BECClient.log $CI_PROJECT_DIR/

  artifacts:
    when: on_failure
    paths:
      - ./*.log
    expire_in: 1 week
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'     
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "production"'


end-2-end-conda:
  stage: End2End
  needs: []
  image: continuumio/miniconda3
  allow_failure: false
  script:
    - apt-get update
    - conda config --prepend channels conda-forge
    - conda config --set channel_priority strict
    - conda config --set always_yes yes --set changeps1 no
    - conda create -q -n test-environment python=3.10
    - conda init bash
    - source ~/.bashrc
    - conda activate test-environment

    # get ophyd devices repo (needed for the device_server)
    - git clone --branch $OPHYD_DEVICES_BRANCH https://oauth2:$CI_OPHYD_DEVICES_KEY@gitlab.psi.ch/bec/ophyd_devices.git
    - export OPHYD_DEVICES_PATH=$PWD/ophyd_devices

    - source ./bin/install_bec_dev.sh -t

    - cd ./bec_client
    - pip install .[dev]
    - pytest --start-servers -v ./tests/end-2-end/test_scans_e2e.py::test_grid_scan

  artifacts:
    when: on_failure
    paths:
      - ./*.log
    expire_in: 1 week

  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "production"'

end-2-end-conda-310:
  stage: End2End
  needs: []
  image: continuumio/miniconda3
  allow_failure: false
  variables:
    PYTHON_VERSION: "3.10"
  script:
    - apt-get update
    - apt-get install -y tmux
    - conda config --set always_yes yes --set changeps1 no
    - conda create -q -n test-environment python=$PYTHON_VERSION
    - conda init bash
    - source ~/.bashrc
    - conda activate test-environment

    - conda install redis
    - redis-server --daemonize yes

    # get ophyd devices repo (needed for the device_server)
    - git clone --branch $OPHYD_DEVICES_BRANCH https://oauth2:$CI_OPHYD_DEVICES_KEY@gitlab.psi.ch/bec/ophyd_devices.git
    - export OPHYD_DEVICES_PATH=$PWD/ophyd_devices

    - *install-bec-services-dev

    - bec-server start --config ./ci/test_config.yaml

    - cd ./bec_client
    - pytest -v ./tests/end-2-end/test_scans_e2e.py

  artifacts:
    when: on_failure
    paths:
      - ./*.log
    expire_in: 1 week

  rules:
    - if: '$E2E_FULL == "1"'

end-2-end-conda-311:
  stage: End2End
  extends: "end-2-end-conda-310"
  allow_failure: false
  variables:
    PYTHON_VERSION: "3.11"

end-2-end-conda-312:
  stage: End2End
  extends: "end-2-end-conda-310"
  allow_failure: false
  variables:
    PYTHON_VERSION: "3.12"

end-2-end-conda-313:
  stage: End2End
  extends: "end-2-end-conda-310"
  allow_failure: true
  variables:
    PYTHON_VERSION: "3.13"

trigger_bec-widgets:
  trigger:
    project: bec/bec-widgets
    strategy: depend
  variables:
    BEC_CORE_BRANCH: $CI_COMMIT_REF_NAME
  rules:
    - if: '$CI_PIPELINE_SOURCE == "web"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "production"'

trigger_ophyd-devices:
  trigger:
    project: bec/ophyd_devices
    strategy: depend
  variables:
    BEC_CORE_BRANCH: $CI_COMMIT_REF_NAME
  rules:
    - if: '$CI_PIPELINE_SOURCE == "web"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"'
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "production"'

semver:
  stage: Build
  needs: ["tests"]
  script:
    - git config --global user.name "ci_update_bot"
    - git config --global user.email "ci_update_bot@bec.ch"
    - git checkout "$CI_COMMIT_REF_NAME"
    - git reset --hard origin/"$CI_COMMIT_REF_NAME"

    # delete all local tags
    - git tag -l | xargs git tag -d
    - git fetch --tags
    - git tag

    # build
    - pip install python-semantic-release==7.* wheel
    - export GL_TOKEN=$CI_UPDATES
    - export REPOSITORY_USERNAME=__token__
    - export REPOSITORY_PASSWORD=$CI_PYPI_TOKEN
    - >
      semantic-release publish -v DEBUG
      -D version_variable=./semantic_release/__init__.py:__version__,./bec_client/setup.py:__version__,./bec_lib/setup.py:__version__,./data_processing/setup.py:__version__,./device_server/setup.py:__version__,./file_writer/setup.py:__version__,./scan_bundler/setup.py:__version__,./scan_server/setup.py:__version__,./scihub/setup.py:__version__,./bec_server/setup.py:__version__
      -D hvcs=gitlab
      -D build_command="./ci/build_python_services.sh"

  allow_failure: false
  rules:
    - if: '$CI_COMMIT_REF_NAME == "master"'

dev-pages:
  stage: Deploy
  needs: ["formatter"]
  rules:
    - if: $CI_COMMIT_REF_NAME == "development"
  script:
    - git config --global user.name "ci_update_bot"
    - git config --global user.email "ci_update_bot@bec.ch"
    - git tag -f development "$CI_COMMIT_SHA"
    - git push --force origin development

    - curl -X POST -d "branches=development" -d "token=$RTD_TOKEN" https://readthedocs.org/api/v2/webhook/beamline-experiment-control/221870/
    - curl -X POST -d "branches=development" -d "token=$RTD_TOKEN_BEC" https://readthedocs.org/api/v2/webhook/bec/246899/

pages:
  stage: Deploy
  needs: ["semver"]
  variables:
    TARGET_BRANCH: $CI_COMMIT_REF_NAME
  rules:
    - if: '$CI_COMMIT_TAG != null'
      variables:
        TARGET_BRANCH: $CI_COMMIT_TAG
    - if: '$CI_COMMIT_REF_NAME == "master"'
    - if: '$CI_COMMIT_REF_NAME == "production"'
  script:
    - curl -X POST -d "branches=$CI_COMMIT_REF_NAME" -d "token=$RTD_TOKEN" https://readthedocs.org/api/v2/webhook/beamline-experiment-control/221870/
    - curl -X POST -d "branches=$CI_COMMIT_REF_NAME" -d "token=$RTD_TOKEN_BEC" https://readthedocs.org/api/v2/webhook/bec/246899/
